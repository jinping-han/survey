
## Part 2: Foundational Word Models

* DreamerV3: Mastering diverse control tasks through world models [[Paper]](https://www.nature.com/articles/s41586-025-08744-2.pdf)   ![](https://img.shields.io/badge/Nature-2025-0077c2)
*  Dreamer: Dream to control: Learning behaviors by latent imagination [[Paper]](https://iclr.cc/virtual_2020/poster_S1lOTC4tDS.html) ![](https://img.shields.io/badge/ICLR-2020-0077c2)
### 2.1 Reinforcement Learning-Based World Models
* DreamSmooth: Improving model-based reinforcement learning via reward smoothing [[Paper]](https://iclr.cc/virtual/2024/poster/19014) ![](https://img.shields.io/badge/ICLR-2024-0077c2)
* PlaNet: Learning latent dynamics for planning from pixels [[Paper]](https://icml.cc/virtual/2019/poster/3764) ![](https://img.shields.io/badge/ICML-2019-0077c2)
* DreamerV2: Mastering atari with discrete world models [[Paper]](https://iclr.cc/virtual/2021/poster/2742) ![](https://img.shields.io/badge/ICLR-2021-0077c2)
* PIGDreamer: Privileged information guided world models for safe partially [[Paper]](https://icml.cc/virtual/2025/poster/44134) ![](https://img.shields.io/badge/ICML-2025-0077c2)
* HarmonyDream: Task Harmonization Inside World Models [[Paper]](https://icml.cc/virtual/2024/poster/32730) ![](https://img.shields.io/badge/ICML-2024-0077c2)
* DyMoDreamer: World modeling with dynamic modulation [[Paper]](https://neurips.cc/virtual/2025/loc/san-diego/poster/117925) ![](https://img.shields.io/badge/NeurIPS-2025-0077c2)
* TD-MPC2: Scalable, robust world models for continuous control  [[Paper]](https://iclr.cc/virtual/2024/poster/18722) ![](https://img.shields.io/badge/ICLR-2024-0077c2)
* Hieros: Hierarchical imagination on structured state space sequence world models [[Paper]](https://icml.cc/virtual/2024/poster/34428) ![](https://img.shields.io/badge/ICML-2024-0077c2)
* THICK: Learning hierarchical world models with adaptive temporal abstractions from discrete latent dynamics [[Paper]](https://iclr.cc/virtual/2024/poster/18558) ![](https://img.shields.io/badge/ICLR-2024-0077c2)
* MoSim: Neural motion simulator pushing the limit of world models in reinforcement learning [[Paper]](https://cvpr.thecvf.com/virtual/2025/poster/34450) ![](https://img.shields.io/badge/CVPR-2025-0077c2)
* R2I: Mastering memory tasks with world models [[Paper]](https://iclr.cc/virtual/2024/poster/19565) 
![](https://img.shields.io/badge/ICLR-2024-0077c2)
* LEQ: Model-based offline reinforcement learning with lower expectile q-learning [[Paper]](https://iclr.cc/virtual/2025/37540) ![](https://img.shields.io/badge/ICLR-2025-0077c2)
* DIMA: Revisiting multi-agent world modeling from a diffusion-inspired perspective [[Paper]](https://neurips.cc/virtual/2025/loc/san-diego/poster/115775) ![](https://img.shields.io/badge/NeurIPS-2025-0077c2)
* PCM: Policy-conditioned environment models are more generalizable [[Paper]](https://icml.cc/virtual/2024/poster/33439) ![](https://img.shields.io/badge/ICML-2024-0077c2)
* CoWorld: Making offline RL online: Collaborative world models for offline visual reinforcement learning [[Paper]](https://neurips.cc/virtual/2024/poster/93263) ![](https://img.shields.io/badge/NeurIPS-2024-0077c2)
* IQ-MPC: Reward-free world models for online imitation learning [[Paper]](https://icml.cc/virtual/2025/poster/44035) ![](https://img.shields.io/badge/ICML-2025-0077c2)
* WAKER: Reward-free curricula for training robust world models [[Paper]](https://proceedings.iclr.cc/paper_files/paper/2024/hash/0a2b3e9107efed3d361b29f300a903ff-Abstract-Conference.html) ![](https://img.shields.io/badge/ICLR-2024-0077c2)
* REM: Improving token-based world models with parallel observation prediction [[Paper]](https://icml.cc/virtual/2024/poster/34279) ![](https://img.shields.io/badge/ICML-2024-0077c2)
* cRSSM: Dreaming of many worlds: Learning contextual world models aids zero-shot generalization [[Paper]](https://openreview.net/pdf?id=zHt4K5zX4P) ![](https://img.shields.io/badge/EWRL-2024-0077c2)
* Adaptive world models: Learning behaviors by latent imagination under non-stationarity $$$ [[Paper]](https://neurips.cc/virtual/2024/104950) ![](https://img.shields.io/badge/NeurIPS-2024-0077c2)
* PWM: Policy learning with multi-task world models [[Paper]](https://iclr.cc/virtual/2025/poster/28766) ![](https://img.shields.io/badge/ICLR-2025-0077c2)
### 2.2 Observation-Level Generative World Models
* 4D-fy: Text-to-4d generation using hybrid score distillation sampling [[Paper]](https://cvpr.thecvf.com/virtual/2024/poster/29662) ![](https://img.shields.io/badge/CVPR-2024-0077c2)
* Sora: Video generation models as world simulators [[Paper]](https://openai.com/index/video-generation-models-as-world-simulators/) ![](https://img.shields.io/badge/OpenAI-2024-0077c2)
* RAP: Reasoning with language model is planning with world model [[Paper]](https://aclanthology.org/2023.emnlp-main.507/) ![](https://img.shields.io/badge/EMNLP-2023-0077c2)
* LWM: World model on million-length video and language with blockwise ringattention [[Paper]](https://iclr.cc/virtual/2025/poster/30229) ![](https://img.shields.io/badge/ICRL-2025-0077c2)
* Making large language models into world models with precondition and effect knowledge $$$ [[Paper]](https://aclanthology.org/2025.coling-main.503.pdf) ![](https://img.shields.io/badge/COLING-2025-0077c2)
* VideoCrafter2: Overcoming data limitations for high-quality video diffusion models [[Paper]](https://cvpr.thecvf.com/virtual/2024/poster/29306) ![](https://img.shields.io/badge/CVPR-2024-0077c2)
* WonderJourney: Going from anywhere to everywhere [[Paper]](https://cvpr.thecvf.com/virtual/2024/poster/31689) ![](https://img.shields.io/badge/CVPR-2023-0077c2)
#### 2.2.1 Language Observations
* Can language models serve as text-based world simulators? $$$[[Paper]](https://aclanthology.org/2024.acl-short.1/) ![](https://img.shields.io/badge/ACL-2024-0077c2)
* GPT-4: Gpt-4 technical report [[Paper]](https://arxiv.org/pdf/2303.08774) ![](https://img.shields.io/badge/arXiv-2023.03-B31B1B)
* Llama 3: The llama 3 herd of models [[Paper]](https://arxiv.org/pdf/2407.21783) ![](https://img.shields.io/badge/arXiv-2024.07-B31B1B)
* LLMCWM: Language agents meet causality â€“ bridging LLMs and causal world models [[Paper]](https://proceedings.iclr.cc/paper_files/paper/2025/hash/5c5bc3553815adb4d1a8a5b8701e41a9-Abstract-Conference.html) ![](https://img.shields.io/badge/ICLR-2025-0077c2)
* Surge: On the potential of large language mode [[Paper]](https://aclanthology.org/2025.emnlp-main.162/) ![](https://img.shields.io/badge/EMNLP-2025-0077c2)
#### 2.2.2 Visual Observations 
* Emu3: Next-token prediction is all you need [[Paper]](https://arxiv.org/pdf/2409.18869) ![](https://img.shields.io/badge/arXiv-2024.09-B31B1B)
* Video world models with long-term spatial memory $$$ [[Paper]](https://neurips.cc/virtual/2025/poster/118886) ![](https://img.shields.io/badge/NeurIPS-2025-0077c2)
* Wan: Open and Advanced Large-Scale Video Generative Models [[Paper]](https://arxiv.org/pdf/2503.20314) ![](https://img.shields.io/badge/arXiv-2025.03-B31B1B)
* LLaVA: Visual instruction tuning [[Paper]](https://papers.neurips.cc/paper_files/paper/2023/hash/6dcf277ea32ce3288914faf369fe6de0-Abstract-Conference.html) ![](https://img.shields.io/badge/NeurIPS-2023-0077c2)
* Vid2world: Crafting video diffusion models to interactive world models [[Paper]](https://arxiv.org/pdf/2505.14357) ![](https://img.shields.io/badge/arXiv-2025.05-B31B1B)
* IRASim: A Fine-Grained World Model for Robot Manipulation [[Paper]](https://iccv.thecvf.com/virtual/2025/poster/2655) ![](https://img.shields.io/badge/ICCV-2025-0077c2)
* CoLA-World: Co-Evolving Latent Action World Models [[Paper]](https://arxiv.org/pdf/2510.26433) ![](https://img.shields.io/badge/arXiv-2025.10-B31B1B)
#### 2.2.3 3D and 4D Observations
* SceneScape: Text-driven consistent scene generation [[Paper]](https://proceedings.neurips.cc/paper_files/paper/2023/hash/7d62a85ebfed2f680eb5544beae93191-Abstract-Conference.html) ![](https://img.shields.io/badge/NeurIPS-2023-0077c2)
* LiDARCrafter: Dynamic 4d world modeling from lidar sequences [[Paper]](https://arxiv.org/pdf/2508.03692v2) ![](https://img.shields.io/badge/arXiv-2025.08-B31B1B)
* Text2room: Extracting textured 3d meshes from 2d text-to-image models [[Paper]](https://openaccess.thecvf.com/content/ICCV2023/html/Hollein_Text2Room_Extracting_Textured_3D_Meshes_from_2D_Text-to-Image_Models_ICCV_2023_paper.html) ![](https://img.shields.io/badge/ICCV-2023-0077c2)
* WonderWorld: Interactive 3d scene generation from a single image [[Paper]](https://cvpr.thecvf.com/virtual/2025/poster/33364) ![](https://img.shields.io/badge/CVPR-2025-0077c2)
* Invisible Stitch: Generating smooth 3d scenes with depth inpainting [[Paper]](https://openreview.net/attachment?id=grImaQQkFx&name=pdf) ![](https://img.shields.io/badge/3DV-2024-0077c2)
